{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Scraping multiple products on Amazon</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Loading environment variable\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Functions to extract meta data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_name(soup):\n",
    "  try:\n",
    "    title = soup.find('span', attrs={'id':'productTitle'})\n",
    "    title_value = title.text\n",
    "    title_string = title_value.strip()\n",
    "\n",
    "  except AttributeError:\n",
    "    title_string = ''\n",
    "  \n",
    "  return title_string\n",
    "\n",
    "def get_product_price(soup):\n",
    "  try:\n",
    "    price = soup.find('span', attrs={'id':'priceblock_ourprice'}).string.strip()\n",
    "\n",
    "  except AttributeError:\n",
    "    try:\n",
    "      price = soup.find('span', attrs={'id':'priceblock_dealprice'}).string.strip()\n",
    "    except:\n",
    "      price = ''\n",
    "\n",
    "  return price\n",
    "\n",
    "def get_available_stock(soup):\n",
    "  try:\n",
    "    available_stock = soup.find('div', attrs={'class': 'a-section a-spacing-base a-spacing-top-micro'}).string.strip()\n",
    "  except AttributeError:\n",
    "    available_stock = 'No Limited Stock'\n",
    "  \n",
    "  return available_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "  #User_Agent = os.environ.get('USER_AGENT')\n",
    "  HEADERS = ({'User-Agent': '', 'Accept-Language': 'en-US, en;q=0.5'})    \n",
    "      # removed User_Agent -- removing makes it work , more research needed\n",
    "\n",
    "  # URL is based on search results page\n",
    "  URL = 'https://www.amazon.com/s?k=fidget+spinner&ref=nb_sb_noss_2'\n",
    "\n",
    "  webpage = requests.get(URL, headers=HEADERS)    # requesting HTTP of full page\n",
    "\n",
    "  search_results = BeautifulSoup(webpage.content, 'html.parser')\n",
    "\n",
    "  links = search_results.find_all('a', attrs={'class':'a-link-normal s-no-outline'})\n",
    "  link_list = []\n",
    "  for link in links:\n",
    "    link_list.append(link.get('href'))\n",
    "\n",
    "  product_detail = {'title':[], 'price':[]}\n",
    "\n",
    "  for link in link_list:\n",
    "    updated_webpage = requests.get('https://www.amazon.com' + link, headers=HEADERS)\n",
    "\n",
    "    new_search_results = BeautifulSoup(updated_webpage.content, 'html.parser')\n",
    "\n",
    "    product_detail['title'].append(get_product_name(new_search_results))\n",
    "    product_detail['price'].append(get_product_price(new_search_results))\n",
    "\n",
    "  amazon_product_df = pd.DataFrame.from_dict(product_detail)\n",
    "  amazon_product_df.to_csv('amazon_fidget_spinner.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search_results\n",
    "#new_search_results\n",
    "amazon_product_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-py-projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
